高价值：否

标题：
《LLM、VLM驱动下机器人自主与交互的综述与分类》

### 迈向具身代理式人工智能：基于大语言模型和视觉语言模型驱动的机器人自主性与交互的回顾与分类

#### 摘要
包括大型语言模型（LLM）和视觉语言模型（VLM）在内的基础模型，近期为机器人自主性和人机界面带来了新颖的方法。同时，视觉语言动作模型（VLA）或大型行为模型（BLM）正在提升机器人系统的灵活性和能力。这篇综述论文聚焦于朝着代理式应用和架构推进的相关内容。这包括探索类似GPT风格的工具接口的初步尝试，以及更复杂的系统，其中人工智能代理是协调者、规划者、感知行动者或通用接口。此类代理式架构使机器人能够对自然语言指令进行推理、调用API、规划任务序列或协助操作和诊断。除了同行评审的研究外，由于该领域的快速发展性质，我们突出并纳入了社区驱动的项目、ROS包和工业框架，这些展示了新兴趋势。我们提出了一个用于对模型集成方法进行分类的分类法，并对当前文献中代理在不同解决方案中的角色进行了对比分析。

#### 引言
大型语言模型（LLM）和视觉语言模型（VLM）近期为机器人学中的交互和推理带来了新的模式。早期工作专注于端到端管道，将原始感官输入和自然语言直接映射到机器人动作，但人们对使用基础模型作为高级代理的模块化系统的兴趣日益增长。这些代理解释用户意图、生成计划、调用机器人API或与机器人操作系统（ROS）等中间件接口，而不取代底层机器人堆栈。

这种代理式方法有几个优势。通过与现有功能集成，LLM可以在不丢弃经过测试的软件模块的情况下扩展机器人的灵活性和可用性。代理可以对非结构化指令进行推理、选择或排序机器人能力，并通过交互调整响应。最近的例子包括LLM的ROS接口、基于协议的控制层以及协调多个子系统或外部工具的代理。

已有若干综述探讨了基础模型与机器人学的更广泛交叉领域[1, 2, 3, 4, 5]，重点在于多模态架构及其组件，主要强调多模态模型在机器人决策和高级规划中的一般应用，以及特定领域设置（如操作）中低级控制的端到端学习框架。然而，随着具身和通用人工智能代理的最近兴起，迄今为止没有先前的综述检查过人工智能代理与现有控制软件、库或中间件接口的新兴设计模式。此外，许多实际系统（GitHub托管的项目、ROS包或初创原型）尽管在现实世界中的相关性和影响力与日俱增，但在文献中的代表性仍然不足。

本文综述解决了这一差距。我们回顾了机器人学中人工智能代理的近期学术和社区驱动的工作，强调将LLM和VLM定位为智能中介而非直接策略生成器的架构。我们的贡献是双重的：
- 我们讨论机器人学中的代理式人工智能概念，并将其与端到端学习或经典符号规划方法区分开来。
- 我们提出一个跨两个维度的分类法：基础模型的集成方法（第三节，另见图1）和代理角色（第四节，另见图3）。
这些元素共同提供了一种替代观点，更具技术性和应用导向，用于看待基础模型在机器人系统中的应用。

#### 迈向具身代理式人工智能
具身机器人代理的概念在20世纪80年代后期提出，其基础是智能行为源自系统的物理具身及其与环境的持续感觉运动交互[17]。这为早期直接将感知映射到动作的端到端神经模型奠定了基础，实现了无需显式符号推理的自主控制[18, 19, 20]。LLM的出现显著扩展了自主代理的功能范围，使其从范围狭窄、规则驱动的系统转变为更灵活、能够泛化、进行上下文推理和自适应行为的实体[21]。在ChatGPT之前的时代，Code as Policies（CaP）引入了机器人可执行的语言模型生成程序（LMPs），通过代码生成间接调用工具实现反应式和基于视觉的控制。

2022年11月OpenAI的ChatGPT发布标志着具身代理式人工智能轨迹上的重大进展，推动了LLM作为机器人系统基础组件的广泛采用。虽然ROS长期以来是机器人软件集成的标准框架，但将LLM运营为自主代理的初步努力主要针对与ROS兼容的平台。到2023年，早期原型开始明确将LLM与机器人框架集成，主要聚焦于协议集成和LLM与ROS之间的双向通信接口。

该领域的早期探索集中于ROS 2的自然语言接口，包括ros2ai [22]，它扩展了ROS 2命令行接口以使用LLM；以及ROScribe [23]，它是一种使用LLM从高级描述生成ROS代码库的工具（例如，用户描述所需的ROS图（传感器、主题和功能），ROScribe将输出Python代码用于实现该规范的ROS节点和启动文件）。此外，提出了ROS-LLM框架[24]以实现具身智能应用。它提供了一个模板，在配置文件中定义机器人的API，然后处理提示工程和对OpenAI API的调用，有效地充当可定制的代理。同时，微软的ChatGPT for Robotics 引入了基于LLM的机器人控制和编程的模块化方法，为每个机器人定义了特定的高级API，利用提示工程和预定义的函数库实现不同任务和模拟环境中的自然语言控制。在这一阶段，大多数实现采用了聊天机器人风格的设计，部署LLM来解释自由形式的文本输入并生成适用于一般机器人集成的相应命令。

在此基础上，2024年随着为机器人和VLA系统开发专门的LLM接口，实现了具有前所未有的泛化和语义推理能力的机器人控制系统的变革性转变。这些框架使代理能够处理开放式自然语言指令，将其与视觉感知结合，并执行相应动作[14]。RT-2 的显著突破是通过在机器人轨迹数据和互联网规模的视觉语言任务上共同微调预训练的VLM引入了新颖的VLA框架。π₀ [12]通过引入通过流匹配扩散策略的实时连续控制，在单个可微框架中统一了感知、推理和运动生成，推动了该领域的发展。

同时，出现了诸如ROSA（Robot Operating System Agent）、RAI（Robotic AI Agent）[10]和BUMBLE [11]等代理式中间件框架，弥合了基于LLM的推理与传统机器人中间件之间的差距，追求具身人工智能。ROSA于2023年底首次开源，通过实现基于LangChain框架和ReAct（推理与行动）代理范式的LLM代理，在人工智能驱动的机器人控制方面取得了重大进展。其核心创新是将ROS操作抽象为启用工具的Python函数——包括列出可用节点、读取传感器数据、移动关节等。这使ROSA能够将自然语言命令转换为经过验证的机器人动作。ROSA还嵌入了安全机制，如参数验证、约束执行和关键动作的可选人工批准。作者在异构平台上展示了ROSA，包括JPL的Nebula-Spot四足机器人和NVIDIA Isaac Sim环境。然而，其架构与基于ROS的中间件紧密耦合，限制了与非ROS系统的互操作性，并限制了在更广泛背景下的部署。RAI是该领域的另一种方法，作为灵活的具身多代理框架，旨在将LLM推理与机器人系统（例如ROS 2）集成。其架构引入了新颖的分布式范式，其中专门的LLM代理（包括感知模块、任务规划器、运动控制器和安全监视器）通过明确定义的角色协作，以实现并发、实时任务执行，同时维护系统安全和可靠性。该框架的核心组件（代理、连接器和工具）提供了多模式传感和驱动、通过向量存储和预配置代理类型（语音、对话、基于状态的检索增强生成）的集成能力。该框架在动态环境中展示了特殊进展，具有在线重新规划和故障恢复等能力。在物理（Husarion ROSBot XL）和模拟（拖拉机和操作器）平台上均得到验证。然而，该框架受到基于LLM的代理有限的空间推理和不可靠的自我纠正的限制，这反复导致在理解物理边界、物体交互和任务完成方面的失败。BUMBLE（Building-wide MoBiLE Manipulation）是另一个最近的贡献，它使用统一的基于VLM的框架进行全楼移动操作。它集成了开放世界感知、双层记忆系统和广泛的运动技能，允许在扩展的空间和时间范围内有效操作。与严重依赖基于ROS的中间件集成的框架（如ROSA）不同，BUMBLE通过使用预定义的地标图像与导航系统进行更紧密的耦合。虽然这提供了高效和精确的导航，但也引入了限制，例如需要事先手动收集地标图像。尽管如此，BUMBLE的感知和行动能力的结合代表了在解决现实世界环境复杂性方面的重大进步。

另一个值得注意的发展是MCP（Model Context Protocol）服务器的概念，推动了代理式使用并将新能力快速集成到现有工具中（例如，Anthropic的Claude或AI驱动的代码编辑器如Cursor。它们在机器人学中的渗透到目前为止是社区驱动的，有几个项目在GitHub上公开可用。例如，ROS-MCP库[25]连接到AI助手（如Claude）并启用与已安装的ROS 2应用程序的交互。其能力包括（i）启动UI应用程序，包括Gazebo模拟器和RViz可视化器；（ii）ROS资源管理（主题、节点）；（iii）ROS系统交互（发布到主题、调用服务、发送动作目标）；（iv）环境调试；和（v）进程管理（例如，清理正在运行的ROS 2进程）。这代表了与其他提供完整应用系统（如ROSA和RAI）的框架不同的范式转变，MCP服务器采用插件式方法，需要标准的AI助手应用程序。另一个例子是ros-mcp-server [25]，它使用rosbridge通过WebSockets连接到ROS 1或ROS 2系统，并包含特定于里程计和速度控制主题的接口。利用像Claude这样的助手的好处是它们已经具有其他内置工具（如网络搜索），并且能够在沙盒环境中内部运行代码。这开启了实现更高级行为的可能性，而无需额外实现。

机器人学中代理式AI的最后一个也是最近的开源框架由初创公司OpenMind [16]驱动。OpenMind的OM1引入了模块化的、与硬件无关的AI运行时，适用于各种机器人平台。与早期框架（如ROSA和RAI）主要针对与基于ROS的中间件集成不同，OM1通过其去中心化的FABRIC协调协议与众不同。FABRIC实现了异构机器人系统之间的安全身份管理和互操作性，不同于早期系统中常见的集中式编排。虽然OM1利用基于Python的配置并纳入了类似于VLA驱动系统（如RT-2）的感知-行动循环，但它显著强调去中心化。总体而言，OM1代表了朝着更具协作性和灵活性的机器人生态系统迈出的一步。

总之，过去三年中，基础模型和机器人框架的接口和集成方法迅速 proliferate。从ROSA精致的LangChain工具，到社区驱动的MCP服务器，再到定制的行业解决方案，趋势很明显：机器人正在获得更高层次的“AI代理”层，可以理解人类意图并管理机器人自身的软件工具包。

图2以时间线格式说明了过去三年的一些关键里程碑和最具代表性的工作。图的上半部分聚焦于代理导向的方法，而下半部分列出了塑造该领域进展的其他相关模型。更全面的工作列表，包括学术论文和社区项目，可在表II中找到。

#### 机器人学中LLM/VLM/VLA和AI代理的方法
我们提出一个分类法，根据大型语言或基础模型集成到机器人系统的方式对迄今为止的工作进行分类。我们的目标不是聚焦于模型的角色、用例或类型，而是从概念和交互角度对集成进行分类。

为此，我们提出目前基础模型集成到机器人系统的四个主要方向：（i）协议集成，重点是将模型用作协议之间的翻译器（例如，用户输入到预定义工具集）；（ii）接口集成，重点是提供连接用户、机器人系统和环境的交互式方法；（iii）面向编排的集成，模型负责管理资源、工具或子系统；（iv）直接或嵌入式集成，模型作为感知或控制策略，要么端到端，要么作为特定子系统。这些方法在图1中说明。我们还根据其集成方法在表II中对一系列代表性工作进行分类。

##### 协议集成
第一类，也是将LLM等基础模型集成到机器人系统中在概念上最简单的方式，是将它们用作用户输入的翻译器。

例如，ros2ai [22]通过将通用用户提示转换为一个特定的ROS 2命令行接口工具调用来实现这一点。交互是有限的，尽管可能，并且过程主要是单向的。

最近，随着MCP协议成为LLM/VLM中工具使用的事实上的标准，多位作者提出了技术集成[28, 25]。可用的工具可以跨越多个领域：与图形界面的交互（例如，启动模拟器），前面提到的ROS 2命令行接口命令的执行，或与ROS通信范式的连接（发布/订阅特定主题、调用服务或执行动作。实际上，MCP协议与ROS中的服务和动作接口等很好地映射。

一个值得注意的相关方法是code-as-policies ，其中LLM输出Python代码来执行任务（使用预定义的感觉运动动作API）。然后代码在循环中执行。本质上，LLM实时“编程”机器人。

##### 接口集成
保留协议集成的工具调用能力，但增强交互性，我们将那些方法分类为接口集成，其中要么（i）工具的输出（通常是现实世界中的动作）影响未来的命令或模型的额外工具调用；要么（ii）聚焦于用户交互，例如在HRI应用中。

该类别也符合朝着更代理式应用的研究方向，其中基础模型相对于用户命令获得进一步的自主性，执行更复杂的工具调用，并且通常在具有多次迭代和每次迭代多个工具调用的循环中运行。

在这种范式中，用户命令可以保持高层次，而基础模型可以将命令分解为多个工具调用。此外，如ROSA、RAI或BUMBLE，动作或工具调用可能跨越一定时间，需要将动作反馈返回给用户和/或模型。

迄今为止最新的、可以说是最完整的开源代理式系统是OpenMind [16]，这是一项商业努力，已在人形机器人和四足机器人等中得到演示，并正在为智能机器人定义新的以AI为中心的“操作系统”。

##### 面向编排的集成
我们将接口集成与面向编排的集成方法区分开来，因为后者聚焦于资源管理问题，而非与用户的交互。这些主要包括LLM或VLM充当规划者或协调者的方法，通常涉及其他AI代理。

该分类类别跨越集成方法和模型的角色，这在第四节中进行了描述，在第四节中我们进一步描述了规划者和编排代理角色。

##### 嵌入式或直接集成
该类别包括LLM（或其多模态变体）直接生成（i）机器人的动作（端到端方式），或（ii）特定输出（例如，用作感知模块）的方法。这些通常被称为机器人基础模型，属于其端到端变体。这些方法也在现有综述论文[1, 2, 3, 4]中得到很好的涵盖。因此，我们仅在本次综述中包括那些从历史角度最相关或有可能推进更代理式系统的工作。这些工作包括在表II中。

##### 代理式框架
重要的是要注意，更复杂的系统可能跨越多个类别。例如，一个系统可能包含用于用户输入的接口代理、内部协调代理，并且可能将协议和直接代理都作为协调器管理的子系统。然而，迄今为止的大多数工作聚焦于一个特定的集成方法，这归因于该领域相对较低的成熟度。

在这种情况下，我们也可以将RAI或OpenMind等解决方案视为框架，因为它们还提供多代理协调的工具和基础设施以及对专业代理的支持。然而，当前的开发和部署阶段更接近接口集成类。

#### 具有LLM的机器人代理的角色和架构
在我们综述了近期集成LLM的机器人系统后，很明显许多系统的区别不在于它们执行的任务，而在于它们结构化决策、控制和模块化的方式。为了捕捉这些架构区别，我们根据功能设计而非应用领域对代理进行分组。这种视角使我们能够更清晰地比较不同系统如何推理、排序动作、调用工具或技能以及与低级控制器接口。这些代理类型的概述见图3。

##### 规划者代理
在这种范式中，LLM为机器人规划一系列动作，通常通过选择或排序离散技能。LLM不直接控制执行器；相反，它输出高层计划，这些计划由低级控制器落实和执行。这种设计允许LLM专注于推理和分解，同时通过单独的模块确保安全性和可行性。

一个基础性的例子是Google的SayCan [34]，其中LLM（PaLM）生成可能的下一步动作（例如，“拿起罐子”或“移动到厨房”），并由学习的价值函数（可及性模型）根据机器人的当前状态评估每个选项。然后执行最可行的动作由相应的技能模块。类似地，SELP [35]使用LLM生成符号任务计划，然后在执行前进行结构化的安全和效率过滤。ConceptAgent [36]进一步扩展了这一想法，纳入了符号规划器和前提接地模块，能够基于环境反馈进行稳健的任务分解和动态重新规划。

与编排代理——它们在实时中持续与感知、记忆和工具API交互——相比，规划代理预先生成计划或迭代地改进计划，在执行期间与API的交互有限。虽然编排代理充当主动运行时管理器，但规划代理聚焦于任务结构化，并将执行监控留给其他组件。

##### 编排代理
随着机器人系统变得越来越模块化和技能丰富，出现了一类新的代理，其中LLM不是作为单个机器人的规划者，而是作为管理多个技能、组件甚至代理之间交互的协调器。这些系统将LLM视为中央控制器，解释高层任务